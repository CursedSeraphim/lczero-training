{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRvqjyD_S9_I",
    "outputId": "2cd11121-2012-4a08-b72d-56ad54164df0"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/LeelaChessZero/lczero-training.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZXPP74LS-KV",
    "outputId": "e8257551-8d1c-488e-bcb5-4e5fb77d598d"
   },
   "outputs": [],
   "source": [
    "# %cd lczero-training/\n",
    "# !pip install -r tf/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Td2Pg1AUS-SY",
    "outputId": "a98e8c94-2067-4a96-d02d-d09b22e8ef34"
   },
   "outputs": [],
   "source": [
    "# %ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drA0ggXhTDfv",
    "outputId": "0a26c8e6-b585-412b-e6a9-feb377afaa86"
   },
   "outputs": [],
   "source": [
    "# %cd libs\n",
    "# !git clone https://github.com/LeelaChessZero/lczero-common.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbGw3GH8TD3z",
    "outputId": "c1e4492a-1dcd-4cbb-f966-d78c4088c9c7"
   },
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# %ls -l\n",
    "# !./init.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdjDQF1FTKZj",
    "outputId": "ce11aae8-602f-40f3-f07b-8e673fff8eba"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-Jj5M7CTK1V",
    "outputId": "0897a800-822e-4e07-d890-c34a4aa74e81"
   },
   "outputs": [],
   "source": [
    "# %cd tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FnzylS9nTTl4"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "import tfprocess\n",
    "from net import Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "k6vmqncHWw2j"
   },
   "outputs": [],
   "source": [
    "\n",
    "cfg_path = \"../128x10-t60-2.yaml\"\n",
    "net_path = \"../128x10-t60-2-5300.pb.gz\"\n",
    "ignore_errors = False\n",
    "\n",
    "with open(cfg_path,'r') as f:\n",
    "  cfg = yaml.safe_load(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NOkumZ0kW0IM",
    "outputId": "8bbb6fc0-11ab-4396-9afd-c36344f9a8e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  allow_less_chunks: true\n",
      "  input_test: /temp/sergio-v/t60/test/rescored/*/\n",
      "  input_train: /temp/sergio-v/t60/train/rescored/*/\n",
      "  num_chunks: 100000000\n",
      "  test_workers: 8\n",
      "  train_ratio: 0.9\n",
      "  train_workers: 16\n",
      "gpu: all\n",
      "model:\n",
      "  filters: 128\n",
      "  moves_left: v1\n",
      "  residual_blocks: 10\n",
      "  se_ratio: 4\n",
      "  value_channels: 32\n",
      "name: 128x10-2\n",
      "training:\n",
      "  batch_size: 4096\n",
      "  checkpoint_steps: 10000\n",
      "  lr_boundaries:\n",
      "  - 100\n",
      "  lr_values:\n",
      "  - 0.0002\n",
      "  - 0.0002\n",
      "  mask_legal_moves: true\n",
      "  max_grad_norm: 3.0\n",
      "  memory_limit: 9000\n",
      "  moves_left_gradient_flow: 1.0\n",
      "  moves_left_loss_weight: 0.1\n",
      "  num_batch_splits: 4\n",
      "  num_test_positions: 100000\n",
      "  path: /home/s/sergio-v/project/new/networks\n",
      "  policy_loss_weight: 1.0\n",
      "  q_ratio: 0.0\n",
      "  reg_loss_weight: 1.0\n",
      "  renorm: true\n",
      "  renorm_max_d: 0.0\n",
      "  renorm_max_r: 1.0\n",
      "  shuffle_size: 500000\n",
      "  swa: true\n",
      "  swa_max_n: 10\n",
      "  swa_output: true\n",
      "  swa_steps: 25\n",
      "  test_steps: 1000\n",
      "  total_steps: 1000000000\n",
      "  train_avg_report_steps: 100\n",
      "  trainstop_path: /temp/sergio-v/trainstop\n",
      "  value_loss_weight: 1.0\n",
      "  warmup_steps: 125\n",
      "\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(yaml.dump(cfg, default_flow_style=False))\n",
    "# START_FROM = args.start\n",
    "\n",
    "tfp = tfprocess.TFProcess(cfg)\n",
    "tfp.init_net_v2()\n",
    "tfp.replace_weights_v2(net_path, ignore_errors)\n",
    "# tfp.global_step.assign(START_FROM)\n",
    "\n",
    "# root_dir = os.path.join(cfg['training']['path'], cfg['name'])\n",
    "# if not os.path.exists(root_dir):\n",
    "#     os.makedirs(root_dir)\n",
    "# # tfp.manager.save(checkpoint_number=START_FROM)\n",
    "# print(\"Wrote model to {}\".format(tfp.manager.latest_checkpoint))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J2oMPbTAS44H"
   },
   "outputs": [],
   "source": [
    "cfg['dataset']['input_train'] = \"../../drive/MyDrive/icg-chess/supervised-0/*\"\n",
    "cfg['dataset']['input_test'] = \"../../drive/MyDrive/icg-chess/supervised-0/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pP3Rj1TTZrdM",
    "outputId": "acb753cd-1265-4c75-c7df-965b431e6208"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "for d in glob.glob(cfg['dataset']['input_train']):\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5yKTjr2vTJ54",
    "outputId": "8d9d7a95-1d55-43d8-a63f-a21e4d401cd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  allow_less_chunks: true\n",
      "  input_test: ../../drive/MyDrive/icg-chess/supervised-0/*\n",
      "  input_train: ../../drive/MyDrive/icg-chess/supervised-0/*\n",
      "  num_chunks: 100000000\n",
      "  test_workers: 8\n",
      "  train_ratio: 0.9\n",
      "  train_workers: 16\n",
      "gpu: all\n",
      "model:\n",
      "  filters: 128\n",
      "  moves_left: v1\n",
      "  residual_blocks: 10\n",
      "  se_ratio: 4\n",
      "  value_channels: 32\n",
      "name: 128x10-2\n",
      "training:\n",
      "  batch_size: 4096\n",
      "  checkpoint_steps: 10000\n",
      "  lr_boundaries:\n",
      "  - 100\n",
      "  lr_values:\n",
      "  - 0.0002\n",
      "  - 0.0002\n",
      "  mask_legal_moves: true\n",
      "  max_grad_norm: 3.0\n",
      "  memory_limit: 9000\n",
      "  moves_left_gradient_flow: 1.0\n",
      "  moves_left_loss_weight: 0.1\n",
      "  num_batch_splits: 4\n",
      "  num_test_positions: 100000\n",
      "  path: /home/s/sergio-v/project/new/networks\n",
      "  policy_loss_weight: 1.0\n",
      "  q_ratio: 0.0\n",
      "  reg_loss_weight: 1.0\n",
      "  renorm: true\n",
      "  renorm_max_d: 0.0\n",
      "  renorm_max_r: 1.0\n",
      "  shuffle_size: 500000\n",
      "  swa: true\n",
      "  swa_max_n: 10\n",
      "  swa_output: true\n",
      "  swa_steps: 25\n",
      "  test_steps: 1000\n",
      "  total_steps: 1000000000\n",
      "  train_avg_report_steps: 100\n",
      "  trainstop_path: /temp/sergio-v/trainstop\n",
      "  value_loss_weight: 1.0\n",
      "  warmup_steps: 125\n",
      "\n",
      "got 0 chunks for ../../drive/MyDrive/icg-chess/supervised-0/*\n",
      "sorting 0 chunks...[done]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-75776c4e96ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown dataset sort_type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'input_test'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     train_chunks = get_latest_chunks(cfg['dataset']['input_train'],\n\u001b[0m\u001b[1;32m     23\u001b[0m                                       1, allow_less, sort_key_fn)\n\u001b[1;32m     24\u001b[0m     test_chunks = get_latest_chunks(cfg['dataset']['input_test'], 1,\n",
      "\u001b[0;32m~/Desktop/work/chess_embedding/lczero-training/tf/train.py\u001b[0m in \u001b[0;36mget_latest_chunks\u001b[0;34m(path, num_chunks, allow_less, sort_key_fn)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mchunks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_key_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[done]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             print(\"{} - {}\".format(os.path.basename(chunks[-1]),\n\u001b[0m\u001b[1;32m     63\u001b[0m                                    os.path.basename(chunks[0])))\n\u001b[1;32m     64\u001b[0m             \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from train import get_latest_chunks, get_all_chunks, get_chunks\n",
    "\n",
    "print(yaml.dump(cfg, default_flow_style=False))\n",
    "\n",
    "num_chunks = cfg['dataset']['num_chunks']\n",
    "allow_less = cfg['dataset'].get('allow_less_chunks', False)\n",
    "train_ratio = cfg['dataset']['train_ratio']\n",
    "experimental_parser = cfg['dataset'].get('experimental_v5_only_dataset',\n",
    "                                          False)\n",
    "num_train = int(num_chunks * train_ratio)\n",
    "num_test = num_chunks - num_train\n",
    "sort_type = cfg['dataset'].get('sort_type', 'mtime')\n",
    "if sort_type == 'mtime':\n",
    "    sort_key_fn = os.path.getmtime\n",
    "elif sort_type == 'number':\n",
    "    sort_key_fn = game_number_for_name\n",
    "elif sort_type == 'name':\n",
    "    sort_key_fn = identity_function\n",
    "else:\n",
    "    raise ValueError('Unknown dataset sort_type: {}'.format(sort_type))\n",
    "if 'input_test' in cfg['dataset']:\n",
    "    train_chunks = get_latest_chunks(cfg['dataset']['input_train'],\n",
    "                                      1, allow_less, sort_key_fn)\n",
    "    test_chunks = get_latest_chunks(cfg['dataset']['input_test'], 1,\n",
    "                                    allow_less, sort_key_fn)\n",
    "else:\n",
    "    chunks = get_latest_chunks(cfg['dataset']['input'], num_chunks,\n",
    "                                allow_less, sort_key_fn)\n",
    "    if allow_less:\n",
    "        num_train = int(len(chunks) * train_ratio)\n",
    "        num_test = len(chunks) - num_train\n",
    "    train_chunks = chunks[:num_train]\n",
    "    test_chunks = chunks[num_train:]\n",
    "\n",
    "shuffle_size = cfg['training']['shuffle_size']\n",
    "total_batch_size = cfg['training']['batch_size']\n",
    "batch_splits = cfg['training'].get('num_batch_splits', 1)\n",
    "train_workers = cfg['dataset'].get('train_workers', None)\n",
    "test_workers = cfg['dataset'].get('test_workers', None)\n",
    "if total_batch_size % batch_splits != 0:\n",
    "    raise ValueError('num_batch_splits must divide batch_size evenly')\n",
    "split_batch_size = total_batch_size // batch_splits\n",
    "# Load data with split batch size, which will be combined to the total batch size in tfprocess.\n",
    "ChunkParser.BATCH_SIZE = split_batch_size"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chess load data and model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
